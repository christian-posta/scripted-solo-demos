model_list:
  # OpenAI
  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo                          # The `openai/` prefix will call openai.chat.completions.create
      api_key: os.environ/OPENAI_API_KEY
  - model_name: gpt-3.5-turbo-instruct
    litellm_params:
      model: text-completion-openai/gpt-3.5-turbo-instruct # The `text-completion-openai/` prefix will call openai.completions.create
      api_key: os.environ/OPENAI_API_KEY

# Anthropic
  - model_name: claude-3-5-sonnet 
    litellm_params: 
      model: claude-3-5-sonnet-20240620 
      api_key: "os.environ/ANTHROPIC_API_KEY" 
  - model_name: claude-3-haiku
    litellm_params: 
      model: claude-3-haiku-20240307
      api_key: "os.environ/ANTHROPIC_API_KEY"    
  - model_name: claude-sonnet-4
    litellm_params: 
      model: claude-sonnet-4-20250514
      api_key: "os.environ/ANTHROPIC_API_KEY"    

# Gemini
  - model_name: gemini-2.5-flash-lite
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      api_key: os.environ/GEMINI_API_KEY
  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: os.environ/GEMINI_API_KEY

# Bedrock
  - model_name: bedrock-claude-4-sonnet
    litellm_params:
      model: bedrock/anthropic.claude-sonnet-4-20250514-v1:0
      model_id: "arn:aws:bedrock:us-west-2:606469916935:inference-profile/global.anthropic.claude-sonnet-4-20250514-v1:0"

litellm_settings:
  callbacks: ["prometheus"]
  prometheus_metrics_config:
    - group: "performance"
      metrics:
        - "litellm_request_total_latency_metric"
        - "litellm_llm_api_latency_metric"
      include_labels:
        - "model"
        - "requested_model"
