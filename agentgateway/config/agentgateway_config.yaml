# yaml-language-server: $schema=../../schema/local.json
config:
  tracing:
    otlpEndpoint: "http://host.docker.internal:4317"
    randomSampling: 'true'  # String 'true' means always sample (100%)
    fields:
      add:
        authenticated: 'jwt.sub != null'
        gen_ai.system: 'llm.provider'
        gen_ai.request.model: 'llm.request_model'
        gen_ai.response.model: 'llm.response_model'
        gen_ai.usage.input_tokens: 'llm.input_tokens'
        gen_ai.usage.output_tokens: 'llm.output_tokens'
        gen_ai.operation.name: '"chat"'        
  metrics:
    fields:
      add:
        user_id: "jwt.sub" 
        user_name: 'jwt.preferred_username'
  logging:
    fields:
      add:
        user_id: "jwt.sub" 
        user_name: 'jwt.name'
        authenticated: 'jwt.sub != null'
        jwt_act: "jwt.act"
        token_issuer: 'jwt.iss'
        token_audience: 'jwt.aud'       
        model: 'llm.requestModel'
        provider: 'llm.provider'        
        prompt: 'llm.prompt' 
        #request.body: "request.body"
        #request.headers: "request.headers"
binds:
- port: 3000
  listeners:
  - routes:

  # ------------------------------------------------------------
  # OpenAI route
  # ------------------------------------------------------------
    - name: openai
      matches:
      - path:
          pathPrefix: /openai
      backends:
      - ai:
          name: openai
          provider:
            openAI:
              model: gpt-4o
          routes:
            "/v1/chat/completions": completions  # LLM processing
            "*": passthrough                      # Everything else passes through              
      policies:
        urlRewrite:
          path:
            prefix: ""    # This strips the matched /openai prefix
        backendAuth:
          key: ${OPENAI_API_KEY}
        cors:
          allowOrigins: ["*"]
          allowHeaders: ["*"]
          allowMethods: ["GET", "POST", "PUT", "DELETE", "OPTIONS"]
          allowCredentials: false

        ## We require JWT auth for calling this route
        ## it is expected to be coming from an SSO IdP  
        jwtAuth:
          mode: optional
          issuer: http://localhost:8080/realms/mcp-realm
          audiences: [account]
          jwks:
            url: http://${KEYCLOAK_HOST:-localhost}:8080/realms/mcp-realm/protocol/openid-connect/certs       
        
        ## We will require JWT for all calls except OPTIONS
        ## If this is not an OPTIONS request, the jwt.sub must be present
        authorization:
          rules:
            - "request.method == 'OPTIONS'"  # Allow OPTIONS
            - "jwt.sub != null"                    

        # Global rate limiting for OpenAI route
        # We configure REQUESTS based rate limiting on this route
        remoteRateLimit:
          domain: "agentgateway"
          host: "${RATELIMIT_HOST:-localhost}:8081"
          descriptors:
            - entries:
                - key: "route"
                  value: '"openai"'
              type: "requests"
        ai:
          promptGuard:
            request:
              rejection:
                status: 400
                # keep this commented out until we can get this in a release:
                # https://github.com/agentgateway/agentgateway/pull/572
                # headers:
                #   set:
                #     content-type: "application/json"                
                body: |
                  {
                    "error": {
                      "message": "Your request was rejected by our content moderation system",
                      "type": "invalid_request_error",
                      "code": "content_policy_violation"
                    }
                  }                      
              openaiModeration:
                auth:
                  key: ${OPENAI_API_KEY}   
              regex:
                action: mask
                rules:
                - builtin: ssn
                - builtin: creditCard
                - builtin: phoneNumber
                - builtin: email

  # ------------------------------------------------------------
  # Failover OpenAI route
  # ------------------------------------------------------------
    - name: failover-openai
      matches:
      - path:
          pathPrefix: /failover/openai
      policies:
        retry:
          attempts: 2        # Retry once (2 total attempts)
          codes: [429]       # Retry on 429 errors
        urlRewrite:
          path:
            prefix: ""          
      backends:
      - ai:
          groups:
          - providers:
              - name: primary-model
                provider:
                  openAI:
                    model: "gpt-5"
                hostOverride: "localhost:9959"  
                backendAuth:
                  key: "INVALID_KEY_TO_FORCE_FAILURE"

          - providers:
              - name: secondary-model
                provider:
                  openAI:
                    model: "gpt-4o"
                backendAuth:
                  key: ${OPENAI_API_KEY}                
                                 

# ------------------------------------------------------------
# Anthropic route
# ------------------------------------------------------------
    - name: anthropic-claude
      matches:
      - path:
          pathPrefix: /anthropic
      backends:
      - ai:
          name: anthropic
          # note, this means we'll estimate the request token count
          # and use that for rate limit BEFORE sending to backend
          # we will still do a tru-up after the request is processed
          # this will cost a performance penalty but it gets more
          # accurate rate limiting (up to 200ms?)
          # if tokenize is false, the reequest will go through and 
          # only the response with the actual counts will be trued-up
          tokenize: true          
          provider:
            anthropic:
              model: claude-3-5-sonnet-20241022
      policies:
        # Global rate limiting for Anthropic route
        # We configure TOKENS based rate limiting on this route
        remoteRateLimit:
          domain: "agentgateway"
          host: "${RATELIMIT_HOST:-localhost}:8081"
          descriptors:
            - entries:
                - key: "route"
                  value: '"anthropic"'
              type: "tokens"      
        backendAuth:  # Place auth HERE on the provider
          key: ${ANTHROPIC_API_KEY}          
        requestHeaderModifier:    
          add:
            anthropic-dangerous-direct-browser-access: "true"                      
        cors:
          allowOrigins: ["*"]
          allowHeaders: ["*"]
        ai:
          promptGuard:
            request:
              regex:
                action: mask
                rules:
                - builtin: ssn
                - builtin: creditCard
                - builtin: phoneNumber
                - builtin: email          

# ------------------------------------------------------------
# Gemini custom guardrail route
# ------------------------------------------------------------
    - name: guardrail-gemini
      matches:
      - path:
          pathPrefix: /guardrail/gemini
      backends:
      - ai:
          name: gemini
          provider:
            gemini:
              model: gemini-2.5-flash-lite     
      policies:
        backendAuth:
          key: ${GEMINI_API_KEY}    
        ai:
          promptGuard:
            request:
              webhook:
                target: ${CUSTOM_WEBHOOK_HOST_MODELARMOR:-localhost}:7272
                # Optional: forward specific request headers to your webhook
                forwardHeaderMatches:
                - name: authorization
                  value:
                    regex: "Bearer .*"
                - name: x-custom-header
                  value:
                    regex: ".*"                                
                          
# ------------------------------------------------------------
# Gemini route
# ------------------------------------------------------------
    - name: gemini
      matches:
      - path:
          pathPrefix: /gemini
      backends:
      - ai:
          name: gemini
          provider:
            gemini:
              model: gemini-2.5-flash-lite
      policies:
        backendAuth:
          key: ${GEMINI_API_KEY}  
        cors:
          allowOrigins: ["*"]
          allowHeaders: ["*"]
        ai:
          promptGuard:
            request:           
              regex:
                action: mask
                rules:
                - builtin: ssn
                - builtin: creditCard
                - builtin: phoneNumber
                - builtin: email          

# ------------------------------------------------------------
# Bedrock custom guardrail route
# ------------------------------------------------------------
    - name: guardrail-bedrock
      matches:
      - path:
          pathPrefix: /guardrail/bedrock
      backends:
      - ai:
          name: bedrock
          provider:
            bedrock:
              region: us-west-2
              model: global.anthropic.claude-sonnet-4-20250514-v1:0
      policies:
        ai:
          promptGuard:
            request:
              webhook:
                target: ${CUSTOM_WEBHOOK_HOST_MODELARMOR:-localhost}:7273
                # Optional: forward specific request headers to your webhook
                forwardHeaderMatches:
                - name: authorization
                  value:
                    regex: "Bearer .*"
                - name: x-custom-header
                  value:
                    regex: ".*"           

# ------------------------------------------------------------
# Bedrock route
# ------------------------------------------------------------
    - name: bedrock
      matches:
      - path:
          pathPrefix: /bedrock
      backends:
      - ai:
          name: bedrock
          provider:
            bedrock:
              region: us-west-2
              # anthropic.claude-sonnet-4-20250514-v1:0
              # model: arn:aws:bedrock:us-west-2:606469916935:inference-profile/global.anthropic.claude-sonnet-4-20250514-v1:0
              model: global.anthropic.claude-sonnet-4-20250514-v1:0
      policies:
        cors:
          allowOrigins: ["*"]
          allowHeaders: ["*"]
        remoteRateLimit:
          domain: "agentgateway"
          host: "${RATELIMIT_HOST:-localhost}:8081"
          descriptors:
            - entries:
                - key: "route"
                  value: '"bedrock"'
              type: "tokens"   
        ai:
          promptGuard:
            request:
              regex:
                action: mask
                rules:
                - builtin: ssn
                - builtin: creditCard
                - builtin: phoneNumber
                - builtin: email                     
# ------------------------------------------------------------
# MCP route
# ------------------------------------------------------------
    - matches:
      - path:
          exact: /mcp
      backends:
      - mcp:
          targets:
          - name: openapi
            openapi:
              schema:
                file: ${OPEN_API_SCHEMA_PATH:-/app/openapi.json}
              host: petstore.swagger.io:443          
          - name: deepwiki
            mcp:
              host: "mcp.deepwiki.com"
              port: 443
              path: "/mcp"
          - name: microsoft
            mcp:
              host: "learn.microsoft.com"
              port: 443
              path: "/api/mcp"              
          - name: exa-ai
            mcp:
              host: "mcp.exa.ai"
              port: 443
              path: "/mcp"
      policies:
        cors:
          allowOrigins:
          - "*"
          allowHeaders:
          - "*"
          allowMethods:
          - "*"
        backendTLS: {}     
        requestHeaderModifier:
          remove:
          - x-forwarded-for
          - x-forwarded-host
          - x-forwarded-proto

# ------------------------------------------------------------
# Secure MCP route
# ------------------------------------------------------------
    - matches:
      - path:
          exact: /secure/mcp
      - path:
          exact: /.well-known/oauth-protected-resource/secure/mcp
      - path:
          exact: /.well-known/oauth-authorization-server/secure/mcp
      backends:
      - mcp:
          targets:
          - name: deepwiki
            mcp:
              host: "mcp.deepwiki.com"
              port: 443
              path: "/mcp"
          - name: microsoft
            mcp:
              host: "learn.microsoft.com"
              port: 443
              path: "/api/mcp"
      policies:
        cors:
          allowOrigins:
          - "*"
          allowHeaders:
          - "*"
          allowMethods:
          - "*"
        requestHeaderModifier:
          remove:
          - x-forwarded-for
          - x-forwarded-host
          - x-