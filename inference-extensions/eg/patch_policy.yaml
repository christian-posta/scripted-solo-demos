apiVersion: gateway.envoyproxy.io/v1alpha1
kind: EnvoyPatchPolicy
metadata:
  name: custom-response-patch-policy
  namespace: default
spec:
  targetRef:
    group: gateway.networking.k8s.io
    kind: Gateway
    name: inference-gateway
  type: JSONPatch
  jsonPatches:
    # Necessary to create a cluster of the type: ORIGINAL_DST to allow for 
    # direct pod scheduling. Which is heavily utilized in our scheduling.
    # Specifically the field `original_dst_lb_config` allows us to enable
    # `use_http_header` and `http_header_name`. 
    # Source: https://www.envoyproxy.io/docs/envoy/latest/api-v3/config/cluster/v3/cluster.proto
    - type: "type.googleapis.com/envoy.config.cluster.v3.Cluster"
      name: original_destination_cluster
      operation:
        op: add
        path: ""
        value:
          name: original_destination_cluster
          type: ORIGINAL_DST
          original_dst_lb_config:
            use_http_header: true
            http_header_name: "x-gateway-destination-endpoint"
          connect_timeout: 1000s
          lb_policy: CLUSTER_PROVIDED
          dns_lookup_family: V4_ONLY
          circuit_breakers:
            thresholds:
            - max_connections: 40000
              max_pending_requests: 40000
              max_requests: 40000

    # This ensures that envoy accepts untrusted certificates. We tried to explicitly
    # set TrustChainVerification to ACCEPT_UNSTRUSTED, but that actually didn't work
    # and what worked is setting the common_tls_context to empty.
    - type: "type.googleapis.com/envoy.config.cluster.v3.Cluster"
      name: "envoyextensionpolicy/default/ext-proc-policy/extproc/0"
      operation:
        op: add
        path: "/transport_socket"
        value:
          name: "envoy.transport_sockets.tls"
          typed_config:
            "@type": "type.googleapis.com/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext"
            common_tls_context: {}
    - type: "type.googleapis.com/envoy.config.route.v3.RouteConfiguration"
      name: default/inference-gateway/llm-gw
      operation:
        op: replace
        path: "/virtual_hosts/0/routes/0/route/cluster"
        value: original_destination_cluster
# Uncomment the below to enable full duplex streaming
    # - type: "type.googleapis.com/envoy.config.listener.v3.Listener"
    #   name: "default/inference-gateway/llm-gw"
    #   operation:
    #     op: add
    #     path: "/default_filter_chain/filters/0/typed_config/http_filters/0/typed_config/processing_mode/request_body_mode"
    #     value: FULL_DUPLEX_STREAMED
    # - type: "type.googleapis.com/envoy.config.listener.v3.Listener"
    #   name: "default/inference-gateway/llm-gw"
    #   operation:
    #     op: add
    #     path: "/default_filter_chain/filters/0/typed_config/http_filters/0/typed_config/processing_mode/request_trailer_mode"
    #     value: SEND
    # - type: "type.googleapis.com/envoy.config.listener.v3.Listener"
    #   name: "default/inference-gateway/llm-gw"
    #   operation:
    #     op: add
    #     path: "/default_filter_chain/filters/0/typed_config/http_filters/0/typed_config/processing_mode/response_body_mode"
    #     value: FULL_DUPLEX_STREAMED
    # - type: "type.googleapis.com/envoy.config.listener.v3.Listener"
    #   name: "default/inference-gateway/llm-gw"
    #   operation:
    #     op: replace
    #     path: "/default_filter_chain/filters/0/typed_config/http_filters/0/typed_config/processing_mode/response_trailer_mode"
    #     value: SEND
    # - type: "type.googleapis.com/envoy.config.listener.v3.Listener"
    #   name: "default/inference-gateway/llm-gw"
    #   operation:
    #     op: replace
    #     path: "/default_filter_chain/filters/0/typed_config/http_filters/0/typed_config/processing_mode/response_header_mode"
    #     value: SEND

