


# 00-basic-passthrough

Demo it by calling the Open AI API with the following curl command:

kubectl apply -f resources/00-basic-passthrough/upstreams.yaml
kubectl apply -f resources/00-basic-passthrough/http-routes.yaml

OPENAI_API_KEY=<foo>

curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "user",
        "content": "Hello! How are you?"
      }
    ]
  }'

export GATEWAY_IP=$(kubectl get svc gloo-proxy-ai-gateway -n gloo-system -o jsonpath='{.status.loadBalancer.ingress[0].ip}')

curl "$GATEWAY_IP:8080/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [
      {
        "role": "user",
        "content": "Hello! How are you?"
      }
    ]
  }'


  ## 01-call-llm

  kubectl apply -f resources/01-call-llm/llm-providers.yaml
  kubectl apply -f resources/01-call-llm/http-routes.yaml

curl "$GATEWAY_IP:8080/openai"   -H "Content-Type: application/json"   -d '{
  "model": "gpt-3.5-turbo",
  "messages": [
    {                
      "role": "user",
      "content": "Hello! How are you?"
    }
  ]
}'