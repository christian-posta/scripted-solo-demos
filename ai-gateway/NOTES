
# What this Demo shows

* Model / Provider Failover
* Prompt Guard
* Observability
* Rate Limiting
* Credential Injection
* RAG
* Semantic Cache
* NVIDIA NIM on GKE
* NIM Caching
* NIM Operator
* Istio Ambient 
* mTLS for workloads
* Metrics / Observability
* Egress Gateway
* Gloo Gateway / AI Gateway as Istio Waypoint
* For controlling egress AI use traffic

## Prep

NOTE, you must have some routes deployed for this to work. That is, run 00 or 01 to get into the base state. 


## Setting up the demo on Kind
Just run the setup-all.sh script:

```bash
./setup-all.sh
```

Then port forward the following:

Grafana 3000 - the one in monitoring ns
GW 8080 - the ai gateway in gloo-system
UI Server: 6002 - this is running locally on the file system
Jaeger: 16686 - jaeger in the monitoring ns

To set up the Istio parts:

```bash
./setup-istio-demo.sh
```

You can install things piece meal as well. For example, to just install Istio or the Gateway:

```bash
./install-gateway-stable.sh
./install-istio-ambient.sh
```

One of the first things to try is run the load generator and check the metrics in the grafana dashboard.

```bash
cd loadgenerator
./run-local.sh
```



## To run the demo for the UI
* run the UI locally and port forward with ssh port forward
* for each scenario, run the reset-demo.sh script
* for each scenario, run the ff.py script

For example, to run the prompt guard scenario, run the following:

```
./reset-demo.sh --for 5
./ff.py 05-a-prompt-guard.sh
```

As each command is run, you will be prompted to confirm.

Use any printed prompts to test the API from the UI.


## To run the presidio scenario
Make sure to run the ./run-local.sh script to start the presidio service.

## To add prompt logging to the request/responses of access logging:

```bash
kubectl apply -f resources/prompt-logging/route-option.yaml
kubectl apply -f resources/prompt-logging/prompt-logging.yaml
```
